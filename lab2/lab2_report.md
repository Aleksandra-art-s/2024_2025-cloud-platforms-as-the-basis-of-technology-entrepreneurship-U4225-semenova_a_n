
# Лабораторная работа №2: "Исследование Cloud Run"

## Описание:
Это вторая лабораторная работа, направленная на исследование сервиса Cloud Run. В рамках работы был создан сервис, протестирован его функционал, изменены настройки порта, распределен трафик между разными версиями сервиса, а также проанализированы метрики производительности.

## Цель работы:
Ознакомиться с работой Cloud Run, научиться развертывать сервис, управлять версиями и распределением трафика между ними, а также анализировать ключевые метрики производительности.

## Ход работы:

### 1. Создание Cloud Run:
- В первую очередь я развернула сервис на базе дефолтного контейнера `gcr.io/cloudrun/hello`. Сервис был настроен с минимальными ресурсами.
- Развертывание прошло успешно, и сервис стал доступен по предоставленной ссылке [https://hellos-307056602443.us-central1.run.app](https://hellos-307056602443.us-central1.run.app).

![Создание Cloud Run](./IMAGE%202024-10-25%2020:37:29.jpg)
### 2. Тестирование работы сервиса:
- Я перешла по предоставленной ссылке для проверки работы сервиса. В ответе от сервера я получила стандартное сообщение "Hello World", что свидетельствует о корректной работе сервиса.
  
![Тестирование работы сервиса](./IMAGE%202024-10-25%2020:37:32.jpg)
![Тестирование работы сервиса](./IMAGE%202024-10-25%2020:37:34.jpg)
![Тестирование работы сервиса](./IMAGE%202024-10-25%2020:37:37.jpg)
### 3. Анализ метрик и логов:
- После успешного развертывания сервиса я перешла в разделы **Metrics** и **Logs** для анализа показателей работы.

#### Основные показатели метрик:
- **Количество запросов (Request Count)**: Было выполнено 2 успешных запроса с кодом ответа 2xx.
- **Задержка запросов (Request Latencies)**: Средняя задержка при обработке запросов составила около 10 мс.
- **Количество экземпляров контейнера (Container Instance Count)**: Было задействовано 2 экземпляра контейнера для обработки запросов.
- **Использование CPU (Container CPU Utilization)**: Использование процессора находилось на уровне 2-4%.
- **Использование памяти (Container Memory Utilization)**: Использование памяти не превышало 6%.
- **Переданные данные (Sent Bytes)**: Количество отправленных данных составило около 200 байт в секунду.
- **Принятые данные (Received Bytes)**: Принято около 100 байт данных в секунду.
- **Одновременные запросы (Max Concurrent Requests)**: В среднем обрабатывалось до 2 запросов одновременно.

![Показатели метрик](./IMAGE%202024-10-25%2020:37:34.jpg)

### 4. Изменение порта сервиса:
Я изменила порт с 8080 на 8090 через редактирование контейнера. Изменение прошло успешно, и я смогла протестировать сервис на новом порту, убедившись, что он корректно работает.

![Port Change](./IMAGE%202024-10-25%2020:37:37.jpg)

### 5. Управление трафиком между версиями:
Я развернула вторую версию сервиса и распределила трафик между двумя версиями: 100% трафика было направлено на новую ревизию `hellos-00002-prt`. После этого я решила распределить трафик между двумя ревизиями, разделив его между `hellos-00002-prt` и `hellos-00001-8s9`, чтобы сравнить их производительность.

![Port Change](./IMAGE%202024-10-25%2020:37:45.jpg)

![Port Change](./IMAGE%202024-10-25%2020:37:43.jpg)
### 6. Анализ различий между одной и двумя версиями:

#### 1. Нагрузка на контейнеры:
- При использовании одной версии весь трафик обрабатывается одним набором контейнеров. Если бы нагрузка увеличилась, контейнеры могли бы начать масштабироваться для обработки запросов.
- При использовании двух версий трафик распределяется между контейнерами двух ревизий, что снижает нагрузку на каждую из версий. Это видно по количеству активных контейнеров — они начали работать параллельно.

#### 2. Использование CPU и памяти:
- В режиме с одной версией загрузка CPU и памяти была низкой (около 2-4% для CPU и до 6% для памяти).
- При распределении трафика между двумя версиями эти показатели не изменились значительно, что говорит о том, что сервис хорошо масштабируется и эффективно использует ресурсы.
- При распределении трафика между двумя версиями нагрузка на каждый контейнер снизилась, что уменьшает риск перегрузки системы при увеличении трафика.

#### 3. Задержки при обработке запросов:
- При работе одной версии задержка была минимальной — около 10 мс.
- После разделения трафика между двумя версиями задержки остались на том же уровне, что говорит о стабильности работы сервиса независимо от количества ревизий.

#### 4. Масштабирование контейнеров:
- При работе с одной версией сервис масштабировался, активируя контейнеры по мере необходимости.
- В случае двух версий процесс масштабирования стал более гибким — каждый контейнер обрабатывал свою часть трафика, что позволило сохранить стабильную производительность даже при увеличении нагрузки.


### 7. Удаление созданных сервисов:
По завершении тестирования я удалила все созданные сервисы и освободила ресурсы, чтобы избежать ненужных затрат.

---

### Результаты лабораторной работы:
В ходе выполнения лабораторной работы был развернут сервис Cloud Run, протестирована его работа, а также изучены ключевые метрики производительности. Я научилась изменять порт контейнера, управлять несколькими версиями сервиса и распределять трафик между ними.

### Выводы:

- **Распределение нагрузки**: Использование нескольких версий позволяет более равномерно распределить нагрузку, снижая риск перегрузки контейнеров и увеличивая общую стабильность системы.
  
- **Эффективность масштабирования**: Сервис Cloud Run показал хорошую масштабируемость. Даже при увеличении количества запросов и добавлении новой версии, ресурсы использовались эффективно (низкая загрузка CPU и памяти).

- **Гибкость управления трафиком**: Возможность распределять трафик между версиями позволяет гибко управлять развертыванием новых версий, тестировать их в реальном времени без необходимости отключать старую версию.

